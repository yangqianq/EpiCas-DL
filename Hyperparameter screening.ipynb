{
 "cells": [
  {
   "cell_type": "raw",
   "id": "5f301d9b",
   "metadata": {},
   "source": [
    "# This section of the code is mainly modified from https://github.com/izhangcd/DeepHF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "269d10dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-24 19:23:24.746195: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ohpc/pub/mpi/openmpi3-gnu8/3.1.4/lib:/opt/ohpc/pub/compiler/gcc/8.3.0/lib64:/usr/local/cuda/lib64\n",
      "2022-04-24 19:23:24.746225: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from dotmap import DotMap\n",
    "import logging\n",
    "import GPy\n",
    "import GPyOpt\n",
    "from function import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import scipy as sp\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "np.set_printoptions(threshold=np.inf) \n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6878bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create logger with 'Model_application'\n",
    "logger = logging.getLogger('Model')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "# create file handler which logs even debug messages\n",
    "fh = logging.FileHandler('CRISRPoff.log')\n",
    "fh.setLevel(logging.DEBUG)\n",
    "# create formatter and add it to the handlers\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "fh.setFormatter(formatter)\n",
    "logger.addHandler(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d53d0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE = pd.read_csv(\"./dataset/testfile.csv\")\n",
    "data = pd.DataFrame(columns=(['40mer']))\n",
    "data['40mer'] = FILE['40mer']\n",
    "\n",
    "x_data = data.iloc[:, 0]\n",
    "x_data = grna_preprocess(x_data,40)\n",
    "\n",
    "y_data = FILE['efficiency']\n",
    "y_data = np.array(y_data)\n",
    "y_data = y_data.reshape(len(y_data), -1)\n",
    "\n",
    "tss1,tss2,tss3,tss4 = FILE['nor_tss1'],FILE['nor_tss2'],FILE['nor_tss3'],FILE['nor_tss4']\n",
    "tss1,tss2,tss3,tss4 = epi_progress(tss1),epi_progress(tss2),epi_progress(tss3),epi_progress(tss4)\n",
    "Methylation,ATAC,RNA = FILE['nor_methylation'],FILE['nor_atac'],FILE['nor_rna']\n",
    "Methylation,ATAC,RNA = epi_progress(Methylation),epi_progress(ATAC),epi_progress(RNA)\n",
    "model_input = np.concatenate((x_data, tss1, tss2, tss3, tss4, Methylation, ATAC, RNA), axis=3)\n",
    "x_train,x_test,y_train,y_test = train_test_split(model_input, y_data, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebaea624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def EpiCasDL(batch_size = 60, epochs = 60,drop1 = 0.3, drop2 = 0.3, drop3 = 0.3,drop4 = 0.3, filters1 = 40, filters2 = 40, filters3 = 40,\n",
    "             filters4 = 40, filters5 = 40, full_Dense1 = 80, full_Dense2 = 60, full_Dense3 = 40, optimizer = Adam, learning_rate = 0.001,\n",
    "            activation = 'relu'):\n",
    "    data_input = Input(shape = (1,40,11))\n",
    "    data_Conv1 = Conv2D(filters = filters1, kernel_size = (1,1),padding = 'same', activation = 'relu')(data_input)\n",
    "    data_Conv2 = Conv2D(filters = filters2, kernel_size = (1,2),padding = 'same', activation = 'relu')(data_input)\n",
    "    data_Conv3 = Conv2D(filters = filters3, kernel_size = (1,3),padding = 'same', activation = 'relu')(data_input)\n",
    "    data_Conv4 = Conv2D(filters = filters4, kernel_size = (1,4),padding = 'same', activation = 'relu')(data_input)\n",
    "    data_Conv5 = Conv2D(filters = filters5, kernel_size = (1,5),padding = 'same', activation = 'relu')(data_input)\n",
    "    data_t = tf.keras.layers.Concatenate()([data_Conv1, data_Conv2, data_Conv3, data_Conv4, data_Conv5])\n",
    "    data_p = MaxPool2D(strides = 2, padding = 'same')(data_t)\n",
    "    data_d = Dropout(drop1)(data_p)\n",
    "    \n",
    "    flatten = Flatten()(data_d)\n",
    "    f1 = Dense(full_Dense1,activation = 'relu')(flatten)\n",
    "    data_d2 = Dropout(drop2)(f1)\n",
    "    f2 = Dense(full_Dense2,activation = 'relu')(data_d2)\n",
    "    data_d3 = Dropout(drop3)(f2)\n",
    "    f3 = Dense(full_Dense3,activation = 'relu')(data_d3)\n",
    "    data_d4 = Dropout(drop4)(f3)\n",
    "    output = Dense(1,activation = \"linear\", name = \"output\")(data_d4)\n",
    "    model = Model(inputs = [data_input], outputs = [output])\n",
    "    \n",
    "    model.compile(optimizer = Adam(lr=0.0001), loss = 'mse',metrics=['mse'])\n",
    "    early_stopping = EarlyStopping(monitor = 'val_loss', patience=5, verbose = 1)\n",
    "    get_best_model = GetBest('./model/'+'CNN.h5', monitor = 'val_loss', verbose = 1, mode = 'min')\n",
    "    model.fit(x_train,y_train,\n",
    "             batch_size = batch_size,\n",
    "             epochs = epochs,\n",
    "             verbose = 2,\n",
    "             validation_split = 0.2,\n",
    "             callbacks = [get_best_model,early_stopping])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c77be121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# string parameters changed to dictionary which keys are integers\n",
    "fc_activation_dict = {'1':'relu','2':'tanh', '3':'sigmoid', '4':'hard_sigmoid', '0':'elu'}\n",
    "optimizer_dict = {'1':SGD,'2':RMSprop, '3':Adagrad, '4':Adadelta,'5':Adam,'6':Adamax,'0':Nadam}\n",
    "#parameter space\n",
    "bounds = [\n",
    "          #Discrete  \n",
    "          {'name':'drop1','type':'discrete','domain':(0.1, 0.2, 0.3, 0.4, 0.5)},\n",
    "          {'name':'drop2','type':'discrete','domain':(0.1, 0.2, 0.3, 0.4, 0.5)},\n",
    "          {'name':'drop3','type':'discrete','domain':(0.1, 0.2, 0.3, 0.4, 0.5)},\n",
    "          {'name':'drop4','type':'discrete','domain':(0.1, 0.2, 0.3, 0.4, 0.5)},\n",
    "          {'name':'learning_rate','type':'discrete','domain':(0.1, 0.01, 0.02, 0.001, 0.002)},\n",
    "          #Discrete\n",
    "          {'name':'batch_size', 'type': 'discrete','domain': (64,128, 256, 512)},\n",
    "          {'name':'epochs', 'type': 'discrete','domain': (20, 25, 30, 35, 40, 45, 50, 55,60)},\n",
    "          {'name':'filters1', 'type': 'discrete','domain': (20, 30, 40, 50, 60)},\n",
    "          {'name':'filters2', 'type': 'discrete','domain': (20, 30, 40, 50, 60)},\n",
    "          {'name':'filters3', 'type': 'discrete','domain': (20, 30, 40, 50, 60)},\n",
    "          {'name':'filters4', 'type': 'discrete','domain': (20, 30, 40, 50, 60)},\n",
    "          {'name':'filters5', 'type': 'discrete','domain': (20, 30, 40, 50, 60)},\n",
    "          {'name':'full_Dense1', 'type': 'discrete','domain': (40, 60, 80, 90, 100, 150, 200, 250, 300)},\n",
    "          {'name':'full_Dense2', 'type': 'discrete','domain': (40, 60, 80, 90, 100, 150, 200, 250, 300)},\n",
    "          {'name':'full_Dense3', 'type': 'discrete','domain': (40, 60, 80, 90, 100, 150, 200, 250, 300)},\n",
    "          #Categorical\n",
    "          {'name':'activation', 'type': 'categorical','domain':tuple(map(int,tuple(fc_activation_dict.keys())))},\n",
    "          {'name':'optimizer', 'type': 'categorical','domain':tuple(map(int,tuple(optimizer_dict.keys())))}\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "590076b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_decode(x):\n",
    "    opt= DotMap()\n",
    "    opt.drop1 = float(x[:, 0])\n",
    "    opt.drop2 = float(x[:, 1])\n",
    "    opt.drop3 = float(x[:, 2])\n",
    "    opt.drop4 = float(x[:, 3])\n",
    "#     opt.learning_rate = float(x[:, 4])\n",
    "    \n",
    "    opt.batch_size = int(x[:, 5])\n",
    "    opt.epochs = int(x[:, 6]) \n",
    "    opt.filters1 =int(x[:, 7])\n",
    "    opt.filters2 = int(x[:, 8])\n",
    "    opt.filters3 = int(x[:, 9])\n",
    "    opt.filters4 = int(x[:, 10])\n",
    "    opt.filters5 = int(x[:, 11])\n",
    "    opt.full_Dense1 = int(x[:, 12])\n",
    "    opt.full_Dense2 = int(x[:, 13])\n",
    "    opt.full_Dense3 = int(x[:, 14]) \n",
    "    \n",
    "#     opt.activation = int(x[:,15])\n",
    "    opt.optimizer = int(x[:,16])\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d2ce8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    opt = cat_decode(x)\n",
    "    param = {'drop1':opt.drop1,\n",
    "           'drop2':opt.drop2,\n",
    "           'drop3':opt.drop3,\n",
    "           'drop4':opt.drop4,\n",
    "           'learning_rate':opt.learning_rate,\n",
    "\n",
    "           'batch_size':opt.batch_size,\n",
    "           'epochs':opt.epochs, \n",
    "           'filters1':opt.filters1,\n",
    "           'filters2':opt.filters2,\n",
    "           'filters3':opt.filters3,\n",
    "           'filters4':opt.filters4,\n",
    "           'filters5':opt.filters5,\n",
    "           'full_Dense1':opt.full_Dense1,\n",
    "           'full_Dense2':opt.full_Dense2,\n",
    "           'full_Dense3':opt.full_Dense3, \n",
    "\n",
    "           'activation':opt.fc_activation,\n",
    "           'optimizer':opt.optimizer}\n",
    "\n",
    "    model = EpiCasDL(**param)\n",
    "    y_test_pred = model.predict(x_test)\n",
    "    evaluation = mean_squared_error(y_test, y_test_pred)\n",
    "    logger.info('----------')\n",
    "    logger.info('params:{}'.format(param))\n",
    "    logger.info('metrics——mse:{},spearman:{}'.format(evaluation,sp.stats.spearmanr(y_test, y_test_pred)[0]))\n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edce6b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetBest(Callback):\n",
    "    def __init__(self,filepath=None, monitor='val_loss', save_best=False,verbose=0,\n",
    "                 mode='auto', period=1):\n",
    "        super(GetBest, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.verbose = verbose\n",
    "        self.period = period\n",
    "        self.save_best = save_best\n",
    "        self.filepath = filepath\n",
    "        self.best_epochs = 0\n",
    "        self.epochs_since_last_save = 0\n",
    "\n",
    "        if mode not in ['auto', 'min', 'max']:\n",
    "            warnings.warn('GetBest mode %s is unknown, '\n",
    "                          'fallback to auto mode.' % (mode),\n",
    "                          RuntimeWarning)\n",
    "            mode = 'auto'\n",
    "\n",
    "        if mode == 'min':\n",
    "            self.monitor_op = np.less\n",
    "            self.best = np.Inf\n",
    "        elif mode == 'max':\n",
    "            self.monitor_op = np.greater\n",
    "            self.best = -np.Inf\n",
    "        else:\n",
    "            if 'acc' in self.monitor or self.monitor.startswith('fmeasure'):\n",
    "                self.monitor_op = np.greater\n",
    "                self.best = -np.Inf\n",
    "            else:\n",
    "                self.monitor_op = np.less\n",
    "                self.best = np.Inf\n",
    "                \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.best_weights = self.model.get_weights()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        self.epochs_since_last_save += 1\n",
    "        if self.epochs_since_last_save >= self.period:\n",
    "            self.epochs_since_last_save = 0\n",
    "            filepath = self.filepath.format(epoch=epoch + 1, **logs)\n",
    "            current = logs.get(self.monitor)\n",
    "            if current is None:\n",
    "                warnings.warn('Can pick best model only with %s available, '\n",
    "                              'skipping.' % (self.monitor), RuntimeWarning)\n",
    "            else:\n",
    "                if self.monitor_op(current, self.best):\n",
    "                    if self.verbose > 0:\n",
    "                        print('\\nEpoch %05d: %s improved from %0.5f to %0.5f,'\n",
    "                              ' storing weights.'\n",
    "                              % (epoch + 1, self.monitor, self.best,\n",
    "                                 current))\n",
    "                    self.best = current\n",
    "                    self.best_epochs = epoch + 1\n",
    "                    self.best_weights = self.model.get_weights()\n",
    "                    #self.model.save(filepath, overwrite=True)\n",
    "                else:\n",
    "                    if self.verbose > 0:\n",
    "                        print('\\nEpoch %05d: %s did not improve.' %\n",
    "                              (epoch + 1, self.monitor)) \n",
    "                    \n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.verbose > 0:\n",
    "            print('Using epoch %05d with %s: %0.5f.' % (self.best_epochs, self.monitor,\n",
    "                                                       self.best))\n",
    "        self.model.set_weights(self.best_weights)\n",
    "        #self.model.save(self.filepath, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f7a23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#time consuming \n",
    "#set initial_design_numdata and  max_iter as lower integer to reduce searching time\n",
    "opt_model = GPyOpt.methods.BayesianOptimization(f=f, domain=bounds, initial_design_numdata=30)\n",
    "opt_model.run_optimization(max_iter = 300)\n",
    "logger.info(\"optimized loss: {0}\".format(opt_model.fx_opt))\n",
    "for i,v in enumerate(bounds):\n",
    "    name = v['name']\n",
    "    logger.info('parameter {}:{}'.format(name,opt_model.x_opt[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf125239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e9e686",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:xy] *",
   "language": "python",
   "name": "conda-env-xy-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
